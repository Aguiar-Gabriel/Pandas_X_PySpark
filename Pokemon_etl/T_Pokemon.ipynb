{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "Pokemon Number\n",
      "Stat Total\n",
      "HP\n",
      "Attack\n",
      "Defense\n",
      "Sp.Atk\n",
      "Sp.Def\n",
      "Speed\n",
      "Mega\n",
      "First Type\n",
      "Second Type\n",
      "Species\n",
      "First Ability\n",
      "Second Ability\n",
      "Hidden Ability\n",
      "Generation\n",
      "Egg Group 1\n",
      "Egg Group 2\n",
      "Is Sub Legendary\n",
      "Is Legendary\n",
      "Is Mythical\n"
     ]
    }
   ],
   "source": [
    "#Verificando as colunas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Pokemon_Data.csv')\n",
    "for coluna in df.columns:\n",
    "    print(coluna)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Nome_Col = \"Generation\"\n",
    "df = pd.read_csv('Pokemon_Data.csv')\n",
    "\n",
    "df1 = pd.DataFrame({Nome_Col: df['Generation']})\n",
    "\n",
    "\n",
    "df_junta = pd.concat([df1])\n",
    "df_junta.drop_duplicates(subset=Nome_Col, keep='first', inplace=True)\n",
    "df_junta = df_junta.sort_values(by=Nome_Col)\n",
    "df_junta['SK_'+ Nome_Col] = range(1, len(df_junta) + 1)\n",
    "\n",
    "\n",
    "df_junta.to_csv('BD_'+ Nome_Col +'.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Nome_Col = \"Egg\"\n",
    "df = pd.read_csv('Pokemon_Data.csv')\n",
    "\n",
    "df1 = pd.DataFrame({Nome_Col: df['Egg Group 1']})\n",
    "df2 = pd.DataFrame({Nome_Col: df['Egg Group 2']})\n",
    "\n",
    "df_junta = pd.concat([df1, df2])\n",
    "df_junta.drop_duplicates(subset=Nome_Col, keep='first', inplace=True)\n",
    "df_junta = df_junta.sort_values(by=Nome_Col)\n",
    "df_junta['SK_'+ Nome_Col] = range(1, len(df_junta) + 1)\n",
    "\n",
    "\n",
    "df_junta.to_csv('BD_'+ Nome_Col +'.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('Pokemon_Data.csv')\n",
    "coluna_escolhida = df['First Type']\n",
    "coluna_sem_duplicadas = coluna_escolhida.drop_duplicates()\n",
    "print(coluna_sem_duplicadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Nome_Col = \"Type\"\n",
    "df = pd.read_csv('Pokemon_Data.csv')\n",
    "\n",
    "df1 = pd.DataFrame({Nome_Col: df['First Type']})\n",
    "df2 = pd.DataFrame({Nome_Col: df['Second Type']})\n",
    "\n",
    "df_junta = pd.concat([df1, df2])\n",
    "df_junta.drop_duplicates(subset=Nome_Col, keep='first', inplace=True)\n",
    "df_junta = df_junta.sort_values(by=Nome_Col)\n",
    "df_junta['SK_'+ Nome_Col] = range(1, len(df_junta) + 1)\n",
    "\n",
    "\n",
    "df_junta.to_csv('BD_'+ Nome_Col +'.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Nome_Col = \"Ability\"\n",
    "df = pd.read_csv('Pokemon_Data.csv')\n",
    "\n",
    "df1 = pd.DataFrame({Nome_Col: df['First Ability']})\n",
    "df2 = pd.DataFrame({Nome_Col: df['Second Ability']})\n",
    "df3 = pd.DataFrame({Nome_Col: df['Hidden Ability']})\n",
    "\n",
    "df_junta = pd.concat([df1, df2,df3])\n",
    "df_junta.drop_duplicates(subset=Nome_Col, keep='first', inplace=True)\n",
    "df_junta = df_junta.sort_values(by=Nome_Col)\n",
    "df_junta['SK_'+ Nome_Col] = range(1, len(df_junta) + 1)\n",
    "\n",
    "\n",
    "df_junta.to_csv('BD_'+ Nome_Col +'.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def realiza_ETL(nome_arquivo, colunas, nome_saida):\n",
    "    df = pd.read_csv(nome_arquivo)\n",
    "\n",
    "    # Selecionar as colunas desejadas\n",
    "    df_selecionado = df[colunas]\n",
    "\n",
    "    # Concatenar as colunas e remover duplicadas\n",
    "    df_concatenado = pd.concat([df_selecionado[col] for col in colunas], axis=0)\n",
    "    df_concatenado_sem_duplicadas = df_concatenado.drop_duplicates()\n",
    "\n",
    "    # Adicionar coluna contador\n",
    "    df_concatenado_sem_duplicadas['contador'] = range(1, len(df_concatenado_sem_duplicadas) + 1)\n",
    "\n",
    "    # Ordenar por coluna contador\n",
    "    df_concatenado_sem_duplicadas = df_concatenado_sem_duplicadas.sort_values(by='contador')\n",
    "\n",
    "    # Salvar em arquivo CSV\n",
    "    df_concatenado_sem_duplicadas.to_csv(nome_saida, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def replace_with_sk(csv_a_file, sk_b_file, column_name):\n",
    "# Dicionário para armazenar as chaves\n",
    "    sk_dict = {}\n",
    "    \n",
    "    # Ler o arquivo SK_B e armazenar as chaves no dicionário\n",
    "    with open(sk_b_file, 'r') as skf:\n",
    "        sk_reader = csv.reader(skf)\n",
    "        next(sk_reader)\n",
    "        for row in sk_reader:\n",
    "            sk_dict[row[0]] = row[1]\n",
    "    \n",
    "    # Ler o arquivo CSV_A e substituir os valores com as chaves correspondentes\n",
    "    with open(csv_a_file, 'r') as db:\n",
    "        db_reader = csv.reader(db)\n",
    "        headers = next(db_reader)\n",
    "        col_index = headers.index(column_name)\n",
    "        \n",
    "        rows = []\n",
    "        for row in db_reader:\n",
    "            try:\n",
    "                row[col_index] = sk_dict[row[col_index]]\n",
    "                rows.append(row)\n",
    "            except KeyError:\n",
    "                # Se o valor não tiver uma chave correspondente, ele será ignorado\n",
    "                pass\n",
    "    \n",
    "    # Escrever as linhas atualizadas no arquivo CSV_A\n",
    "    with open(csv_a_file, 'w', newline='') as db:\n",
    "        db_writer = csv.writer(db)\n",
    "        db_writer.writerow(headers)\n",
    "        for row in rows:\n",
    "            db_writer.writerow(row)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_sk('Pokemon_Data.csv', 'BD_Type.csv', 'First Type' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_sk('Pokemon_Data.csv', 'BD_Type.csv', 'Second Type')\n",
    "replace_with_sk('Pokemon_Data.csv', 'BD_Ability.csv', 'First Ability')\n",
    "replace_with_sk('Pokemon_Data.csv', 'BD_Ability.csv', 'Second Ability')\n",
    "replace_with_sk('Pokemon_Data.csv', 'BD_Ability.csv', 'Hidden Ability')\n",
    "replace_with_sk('Pokemon_Data.csv', 'BD_Generation.csv', 'Generation')\n",
    "replace_with_sk('Pokemon_Data.csv', 'BD_Egg.csv', 'Egg Group 1')\n",
    "replace_with_sk('Pokemon_Data.csv', 'BD_Egg.csv', 'Egg Group 2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc1a37cd63083f7cb69061bb67f11ee6622bbc28a26690eb8f825fd41edc2219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
